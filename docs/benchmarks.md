# Synthetic Benchmarks

These benchmarks are intentionally synthetic for safe public documentation.
They demonstrate methodology and reproducibility, not claims about a private environment.

## Run

- python scripts/benchmark_synthetic.py --format markdown
- python scripts/benchmark_synthetic.py --format json --output docs/benchmarks.synthetic.json

## Why Synthetic

- No personal, internal, or proprietary data exposure.
- Stable baseline for CI and documentation diffs.
- Easy for contributors to reproduce without special infrastructure.

## Notes

- Use this page as a format template for real internal measurements.
- Keep real production measurements in private systems.
